{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d0e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/acad/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOPIC MODELING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "[1/4] Preparing documents...\n",
      "Filtered 2440 → 2047 docs (min 10 words)\n",
      "\n",
      "[2/4] Creating BERTopic model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 12:46:13,279 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Fitting model (this may take 1-2 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 64/64 [00:49<00:00,  1.28it/s]\n",
      "2025-11-06 12:47:03,321 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-06 12:47:03,322 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2025-11-06 12:47:11,018 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-06 12:47:11,019 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-06 12:47:11,048 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-06 12:47:11,050 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-06 12:47:18,427 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/4] Calculating topic probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Found 10 topics\n",
      "\n",
      "Topic distribution:\n",
      "topic\n",
      "-1    340\n",
      " 0    463\n",
      " 1    251\n",
      " 2    225\n",
      " 3    210\n",
      " 4    210\n",
      " 5    154\n",
      " 6     91\n",
      " 7     41\n",
      " 8     31\n",
      " 9     31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "TOPIC ANALYSIS - REVIEW AND MANUALLY LABEL\n",
      "======================================================================\n",
      "\n",
      "Topic 0:\n",
      "  Keywords: ['github', 'skills', 'github com', 'https github com', 'https github', 'mcp', 'skill', 'md', 'agents', 'coding']\n",
      "  Count: 463 posts\n",
      "  Examples:\n",
      "    1. I am migrating from Cursor to Codex. I wrote a script to help me migrate the Cursor rules that I have written over the last year in different repositories to [AGENTS.md](http://AGENTS.md), which is th...\n",
      "    2. This is my **subjective opinion**, but i literally ran a typical EC2 to ECS migration with codex today via AWS CLI, GH Cli and it ran for 2 hour 43 minutes straight and actually did 80% of the work i ...\n",
      "    3. What’s your biggest pain point?\n",
      "\n",
      "1. Pre-deployment testing and evaluation\n",
      "2. Runtime visibility and debugging\n",
      "3. Control over the complete agentic stack...\n",
      "\n",
      "Topic 1:\n",
      "  Keywords: ['voice', 'account', 'flash', 'button', 'chats', 'assistant', 'phone', 'better', 'cream', 'multiple']\n",
      "  Count: 251 posts\n",
      "  Examples:\n",
      "    1. Billions into the pipeline yet can't even format some passage...\n",
      "    2. I have a galaxy phone and Google assistant was replaced with Gemini. normally it works fine but I am confused by this. ...\n",
      "    3. How can I get it to create accurate images ?...\n",
      "\n",
      "Topic 2:\n",
      "  Keywords: ['questions', 'chats', 'performance', 'atlas', 'option', 'emoji', 'domain', 'kept', 'button', 'download']\n",
      "  Count: 225 posts\n",
      "  Examples:\n",
      "    1. I have been requesting sample test questions tostudy for a certificate. I am  given the choice of A,B,C, or D. After the first couple of questions the answers are never random, and always B. I ask the...\n",
      "    2. i didn't know i could be so mean until recently. i think my patience is breaking, and maybe it's time to stop using AI....\n",
      "    3. I genuinely don't know what to do here. The app updated and suddenly I'm unable to change the model and can't edit any prompts. Should I uninstall and reinstall??...\n",
      "\n",
      "Topic 3:\n",
      "  Keywords: ['xai', 'print', 'area', 'agi', 'musk', 'stats', 'self', 'api', 'elon', 'fuck']\n",
      "  Count: 210 posts\n",
      "  Examples:\n",
      "    1. To make it as short as possible:\n",
      "\n",
      "Could Grok access my Whatsapp and secretly reply on my behalf? A close person had texted me and \"somebody\" replied playfully and a bit over-the top with a emoji i nev...\n",
      "    2. I got \"good catch!\"ed right after seeing the other post...\n",
      "    3. Just see the share link...\n",
      "\n",
      "Topic 4:\n",
      "  Keywords: ['v3', 'api', 'attention', 'r1', 'better', 'llms', 'sparse', 'huggingface', 'cost', 'qwen3']\n",
      "  Count: 210 posts\n",
      "  Examples:\n",
      "    1. [2510.15061] Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models...\n",
      "    2. Prompt: alright. lets make a new universe. it has the same rules as this one but one thing changes. we freeze entropy somehow. it still decays but the heatdeath isnt a thing. actually lets just preten...\n",
      "    3. I attempted to use the service today and encountered two refusals that feel rather useless:\n",
      "\n",
      "1. I requested an image of Pharaoh’s daughter lifting the infant Moses from the Nile. The request was refus...\n",
      "\n",
      "Topic 5:\n",
      "  Keywords: ['systems', 'war', 'color', 'label', 'self', 'comment', 'humans', 'consciousness', 'intelligence', 'agi']\n",
      "  Count: 154 posts\n",
      "  Examples:\n",
      "    1. OpenAI employee talks about how the company actually makes decisions...\n",
      "    2. Most LLMs are optimized to always be right — statistically.\n",
      "Their only goal is to predict the most likely next token, so they can’t ever tell you how wrong a nearby alternative might have been. That’s...\n",
      "    3. Isn't it wild we probably passed the Turing test in the last two years and no one mentions it?...\n",
      "\n",
      "Topic 6:\n",
      "  Keywords: ['v0', 'section', 'added', 'critical', 'questions', 'youtube', 'confirm', 'api', '28', 'sections']\n",
      "  Count: 91 posts\n",
      "  Examples:\n",
      "    1. workshopping your health diagnosis should not count against free quota...\n",
      "    2. I have an essay due tonight and I ran it through ZeroGPT and it says it’s 66% ai, but scribbr says it’s only 17%. Which ai checker is more reliable?...\n",
      "    3. Is it worth paying $20 a month? \n",
      "\n",
      "When do you think it would be a good investment?...\n",
      "\n",
      "Topic 7:\n",
      "  Keywords: ['halloween', 'nano banana', 'banana', 'nano', 'camera', 'man', 'shot', 'photo', 'cinematic', 'tall']\n",
      "  Count: 41 posts\n",
      "  Examples:\n",
      "    1. Genuinely curious what people think, im very prideful of my city and finally figured out what I wanted my tattoo would be that would resonate. Asked AI to make a Tucson inspired one.. how do we feel? ...\n",
      "    2. [Sora's Idea of a 1950's Comic Style Graveyard](https://reddit.com/link/1ofwqjw/video/2hpn2bpzgaxf1/player)\n",
      "\n",
      "...\n",
      "    3. Sora is pretty impressive with nailing brand aesthetics (Apple, Coke, Lego Ads)...\n",
      "\n",
      "Topic 8:\n",
      "  Keywords: ['er', 'hands', 'goddamn', 'heart', 'stress', 'excellent', 'lock', 'repeating', 'lattice', 'fucking']\n",
      "  Count: 31 posts\n",
      "  Examples:\n",
      "    1. I’m 7 messages in and already it’s given me a warning \n",
      "\n",
      "(Context, I was asking it to give me Shakespeare like responses)...\n",
      "    2. Seriously...? Wanna me do that?...\n",
      "    3. Weird glitch (asked a simple question, and it hit me with endless gibberish with some unsettling parts)...\n",
      "\n",
      "Topic 9:\n",
      "  Keywords: ['deepthink', 'chinese', 'recipe', 'dal', 'option', 'lentils', 'dashes', 'r1', 'reply', 'dry']\n",
      "  Count: 31 posts\n",
      "  Examples:\n",
      "    1. I use deepseek app on mobile. Surprised it doesn't automatically when to user search and when not to.\n",
      "Im having to manually enable it.\n",
      "\n",
      "Like I asked what's the weather now in a particular city, it sai...\n",
      "    2. Sometimes when I take a screenshot of a certain part of my screen, I have experienced deepseek having knowledge and adressing parts of the screen that wasnt part of the screenshot I sent to deepseek. ...\n",
      "    3. Sorry if this is something that's been discussed, Im not even sure what to search. \n",
      "\n",
      "So, its been a couple of months since I used DeepSeek and when I logged on for the 1s time since then, every questi...\n",
      "\n",
      "✓ Saved results to reddit_topics_unlabeled.xlsx\n",
      "\n",
      "Sample output:\n",
      "   topic                                              title  prob_topic_0  \\\n",
      "0      2                        Mock Test Answers Always B.      0.096670   \n",
      "1      2  anyone else noticing a dark side of themselves...      0.079246   \n",
      "2      6  workshopping your health diagnosis should not ...      0.132485   \n",
      "3      8                                       Please Help?      0.118102   \n",
      "4      5  OpenAI employee talks about how the company ac...      0.134597   \n",
      "5     -1         AuraOS Version 2.3 -- w/ User Instructions      0.126928   \n",
      "6      2                                       Can't edit??      0.096928   \n",
      "7      5  I built a “dialectical” training harness that ...      0.126890   \n",
      "8      1  Billions into the pipeline yet can't even form...      0.171952   \n",
      "9      7               Asked AI for a Tucson sleeve concept      0.087460   \n",
      "\n",
      "   prob_topic_1  prob_topic_2  \n",
      "0      0.135852      0.302747  \n",
      "1      0.089537      0.258667  \n",
      "2      0.085755      0.398727  \n",
      "3      0.000000      0.000000  \n",
      "4      0.167845      0.043735  \n",
      "5      0.110906      0.114902  \n",
      "6      0.173944      0.244105  \n",
      "7      0.093657      0.065608  \n",
      "8      0.261919      0.000000  \n",
      "9      0.074242      0.105333  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Custom stop words to remove LLM names and generic terms\n",
    "CUSTOM_STOP_WORDS = [\n",
    "    # LLM names\n",
    "    'chatgpt', 'gpt', 'claude', 'gemini', 'bard', 'copilot', 'bing',\n",
    "    'openai', 'anthropic', 'google', 'deepseek', 'llama', 'mistral',\n",
    "    'grok', 'perplexity', 'ai', 'llm', 'model', 'bot',\n",
    "    # Reddit noise\n",
    "    'like', 'just', 'got', 'get', 'really', 'think', 'know',\n",
    "    'trying', 'tried', 'anyone', 'thanks', 'please', 'help',\n",
    "    'question', 'post', 'reddit', 'sub', 'subreddit',\n",
    "    # Generic words\n",
    "    'use', 'using', 'used', 'make', 'made', 'thing', 'things',\n",
    "    'way', 'time', 'new', 'able'\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: PREPARE DOCUMENTS\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_documents(df, min_word_count=10):\n",
    "    \"\"\"\n",
    "    Combine title + selftext and filter short posts.\n",
    "    Returns docs list and filtered dataframe.\n",
    "    \"\"\"\n",
    "    # Combine title and selftext\n",
    "    docs = (df['title'].fillna('') + ' ' + df['selftext'].fillna('')).str.strip()\n",
    "    \n",
    "    # Filter by word count\n",
    "    word_counts = docs.str.split().str.len()\n",
    "    valid_mask = word_counts >= min_word_count\n",
    "    \n",
    "    filtered_docs = docs[valid_mask].tolist()\n",
    "    filtered_df = df[valid_mask].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Filtered {len(df)} → {len(filtered_docs)} docs (min {min_word_count} words)\")\n",
    "    return filtered_docs, filtered_df\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: CREATE BERTOPIC MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def create_topic_model(min_topic_size=20):\n",
    "    \"\"\"\n",
    "    Create BERTopic model with sensible defaults for ~2k documents.\n",
    "    \"\"\"\n",
    "    # Embedding model\n",
    "    embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    # UMAP: Reduce to 5 dimensions (not 10 - too high for 2k docs)\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=15,\n",
    "        n_components=5,\n",
    "        min_dist=0.0,\n",
    "        metric='cosine',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # HDBSCAN clustering\n",
    "    hdbscan_model = HDBSCAN(\n",
    "        min_cluster_size=min_topic_size,\n",
    "        min_samples=5,\n",
    "        metric='euclidean',\n",
    "        cluster_selection_method='eom',\n",
    "        prediction_data=True\n",
    "    )\n",
    "    \n",
    "    # Vectorizer with custom stop words\n",
    "    all_stop_words = list(ENGLISH_STOP_WORDS) + CUSTOM_STOP_WORDS\n",
    "    vectorizer_model = CountVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words=all_stop_words,\n",
    "        min_df=2,\n",
    "        max_df=0.8,\n",
    "        max_features=5000\n",
    "    )\n",
    "    \n",
    "    # Representation model\n",
    "    representation_model = {\n",
    "        \"MMR\": MaximalMarginalRelevance(diversity=0.3),\n",
    "        \"KeyBERT\": KeyBERTInspired()  \n",
    "    }\n",
    "    \n",
    "    # Create model\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        representation_model=representation_model,\n",
    "        top_n_words=10,\n",
    "        min_topic_size=min_topic_size,\n",
    "        calculate_probabilities=False,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return topic_model\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: FIT MODEL AND ADD PROBABILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def fit_and_extract_topics(df, min_topic_size=20, min_word_count=10):\n",
    "    \"\"\"\n",
    "    Complete pipeline: prepare docs → fit model → add probabilities.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"TOPIC MODELING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Prepare documents\n",
    "    print(\"\\n[1/4] Preparing documents...\")\n",
    "    docs, filtered_df = prepare_documents(df, min_word_count)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n[2/4] Creating BERTopic model...\")\n",
    "    topic_model = create_topic_model(min_topic_size)\n",
    "    \n",
    "    # Fit model\n",
    "    print(\"\\n[3/4] Fitting model (this may take 1-2 minutes)...\")\n",
    "    topics, _ = topic_model.fit_transform(docs)\n",
    "    \n",
    "    # Add topics to dataframe\n",
    "    filtered_df['topic'] = topics\n",
    "    \n",
    "    # Calculate probability distributions\n",
    "    print(\"\\n[4/4] Calculating topic probabilities...\")\n",
    "    topic_probs, _ = topic_model.approximate_distribution(docs, min_similarity=0)\n",
    "    \n",
    "    # Get topic IDs (excluding -1 if present in get_topic_info but not in probs)\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    all_topic_ids = [t for t in topic_info['Topic'].tolist() if t != -1]\n",
    "    \n",
    "    # Add probability columns\n",
    "    for i, topic_id in enumerate(all_topic_ids):\n",
    "        if i < topic_probs.shape[1]:\n",
    "            filtered_df[f'prob_topic_{topic_id}'] = topic_probs[:, i]\n",
    "    \n",
    "    print(f\"\\n✓ Found {len(all_topic_ids)} topics\")\n",
    "    print(\"\\nTopic distribution:\")\n",
    "    print(filtered_df['topic'].value_counts().sort_index())\n",
    "    \n",
    "    return filtered_df, topic_model\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: ANALYZE TOPICS FOR MANUAL LABELING\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_topics(topic_model, filtered_df, n_examples=3):\n",
    "    \"\"\"\n",
    "    Display keywords and examples for each topic for manual labeling.\n",
    "    \"\"\"\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TOPIC ANALYSIS - REVIEW AND MANUALLY LABEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for _, row in topic_info[topic_info['Topic'] != -1].iterrows():\n",
    "        topic_id = row['Topic']\n",
    "        keywords = topic_model.get_topic(topic_id)[:10]\n",
    "        \n",
    "        print(f\"\\nTopic {topic_id}:\")\n",
    "        print(f\"  Keywords: {[word for word, _ in keywords]}\")\n",
    "        print(f\"  Count: {row['Count']} posts\")\n",
    "        \n",
    "        # Show examples\n",
    "        examples = filtered_df[filtered_df['topic'] == topic_id]\n",
    "        if len(examples) > 0:\n",
    "            print(f\"  Examples:\")\n",
    "            for i, (_, ex) in enumerate(examples.head(n_examples).iterrows(), 1):\n",
    "                text = ex['selftext'] if pd.notna(ex['selftext']) else ex['title']\n",
    "                print(f\"    {i}. {str(text)[:200]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('reddit_llms_with_image_embeddings.csv')\n",
    "\n",
    "# Run pipeline\n",
    "results_df, model = fit_and_extract_topics(\n",
    "    df, \n",
    "    min_topic_size=30,  # Minimum posts per topic\n",
    "    min_word_count=10   # Minimum words per post\n",
    ")\n",
    "\n",
    "# Analyze topics for manual labeling\n",
    "analyze_topics(model, results_df)\n",
    "\n",
    "# Save results\n",
    "output_file = 'reddit_topics_unlabeled.xlsx'\n",
    "results_df.to_excel(output_file, index=False)\n",
    "print(f\"\\n✓ Saved results to {output_file}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample output:\")\n",
    "cols = ['topic', 'title', 'prob_topic_0', 'prob_topic_1', 'prob_topic_2']\n",
    "display_cols = [c for c in cols if c in results_df.columns]\n",
    "print(results_df[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64358f1b",
   "metadata": {},
   "source": [
    "1.  **Topic 0:** **Use Case: Coding & Development**\n",
    "    * *Analysis:* Keywords like `github`, `coding`, `skills`, `agents`, `mcp` strongly point to programming. Examples discuss migrating code editors (`Cursor` to `Codex`), using command-line tools (`AWS CLI`, `GH Cli`), and agentic stacks.\n",
    "\n",
    "2.  **Topic 1:** **Discussion: User Experience & Features (Mobile/Voice/Image)**\n",
    "    * *Analysis:* Keywords `voice`, `assistant`, `phone` suggest mobile/voice interaction (confirmed by Ex 2 about Gemini replacing Assistant). `chats`, `account` point to general usage. Ex 1 (formatting) and Ex 3 (image accuracy) highlight specific feature pain points. It's a bit mixed but revolves around how users interact with features.\n",
    "\n",
    "3.  **Topic 2:** **Pain Point: Interaction Quality & App Issues**\n",
    "    * *Analysis:* Examples focus on problems during interaction: poor quality answers (Ex 1 - test questions), general frustration (Ex 2 - patience breaking), and application bugs (Ex 3 - update issues). Keywords `questions`, `chats`, `performance` align with this.\n",
    "\n",
    "4.  **Topic 3:** **Discussion: Specific LLMs (Grok/xAI), AGI & Probing**\n",
    "    * *Analysis:* Keywords `agi`, `musk`, `elon`, `xai` and Ex 1 (Grok accessing Whatsapp) point to discussions about specific models (Grok) and AGI. Keywords like `api`, `self` and Ex 2 (\"good catch!\") suggest general probing of capabilities and limitations.\n",
    "\n",
    "5.  **Topic 4:** **Discussion: Technical Model Capabilities & Limits**\n",
    "    * *Analysis:* Keywords are highly technical (`v3`, `attention`, `sparse`, `huggingface`, `api`, `cost`, `qwen3`). Ex 1 (paper on models) fits perfectly. Ex 2 (abstract prompt) and Ex 3 (image refusal) explore the boundaries of model capabilities.\n",
    "\n",
    "6.  **Topic 5:** **Discussion: AI Consciousness, Intelligence & Philosophy**\n",
    "    * *Analysis:* Keywords (`consciousness`, `intelligence`, `agi`, `humans`, `self`) and examples (OpenAI decisions, statistical nature vs truth, Turing test) all indicate high-level, philosophical discussions about the nature and implications of AI.\n",
    "\n",
    "7.  **Topic 6:** **Discussion: Usage Limits, Reliability & Subscription Value**\n",
    "    * *Analysis:* Examples directly address practical concerns: usage quotas (Ex 1 - health diagnosis), tool reliability (Ex 2 - AI checkers), and cost vs. benefit (Ex 3 - $20/month).\n",
    "\n",
    "8.  **Topic 7:** **Use Case: Image & Video Generation (Creative)**\n",
    "    * *Analysis:* Keywords (`photo`, `camera`, `cinematic`, `nano banana`) point strongly to image generation. Examples confirm this (tattoo design) and expand to video (Sora examples).\n",
    "\n",
    "9.  **Topic 8:** **Pain Point: Content Filters & Frustrating Interactions**\n",
    "    * *Analysis:* Keywords express strong negative emotion (`goddamn`, `stress`, `fucking`, `repeating`). Examples show users hitting content warnings (Ex 1 - Shakespeare), getting nonsensical output (Ex 3 - gibberish), or facing other confusing/annoying responses.\n",
    "\n",
    "10. **Topic 9:** **Discussion: Specific LLM (DeepSeek) - Usage & Capabilities**\n",
    "    * *Analysis:* Keywords (`deepthink` likely means DeepSeek) and all examples explicitly mention or relate to the DeepSeek model, discussing its mobile app behavior and specific functionalities or quirks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee3736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved new labeled results to reddit_topics_LABELED.xlsx\n",
      "\n",
      "Here's a sample of your newly labeled data:\n",
      "   topic                                              label  \\\n",
      "0      2       Pain Point: Interaction Quality & App Issues   \n",
      "1      2       Pain Point: Interaction Quality & App Issues   \n",
      "2      6  Discussion: Usage Limits, Reliability & Subscr...   \n",
      "3      8  Pain Point: Content Filters & Frustrating Inte...   \n",
      "4      5  Discussion: AI Consciousness, Intelligence & P...   \n",
      "5     -1                                            Outlier   \n",
      "6      2       Pain Point: Interaction Quality & App Issues   \n",
      "7      5  Discussion: AI Consciousness, Intelligence & P...   \n",
      "8      1  Discussion: User Experience & Features (Mobile...   \n",
      "9      7      Use Case: Image & Video Generation (Creative)   \n",
      "\n",
      "                                               title  \\\n",
      "0                        Mock Test Answers Always B.   \n",
      "1  anyone else noticing a dark side of themselves...   \n",
      "2  workshopping your health diagnosis should not ...   \n",
      "3                                       Please Help?   \n",
      "4  OpenAI employee talks about how the company ac...   \n",
      "5         AuraOS Version 2.3 -- w/ User Instructions   \n",
      "6                                       Can't edit??   \n",
      "7  I built a “dialectical” training harness that ...   \n",
      "8  Billions into the pipeline yet can't even form...   \n",
      "9               Asked AI for a Tucson sleeve concept   \n",
      "\n",
      "                                            selftext  \n",
      "0  I have been requesting sample test questions t...  \n",
      "1  i didn't know i could be so mean until recentl...  \n",
      "2                                                NaN  \n",
      "3  I’m 7 messages in and already it’s given me a ...  \n",
      "4                                                NaN  \n",
      "5  \\[2025-10-25 23:11:15 ADT\\] Understood. Modify...  \n",
      "6  I genuinely don't know what to do here. The ap...  \n",
      "7  Most LLMs are optimized to always be right — s...  \n",
      "8                                                NaN  \n",
      "9  Genuinely curious what people think, im very p...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \"wishlist\" keys\n",
    "topic_label_map = {\n",
    "    -1: \"Outlier\", # From original notebook analysis\n",
    "    0: \"Use Case: Coding & Development\",\n",
    "    1: \"Discussion: User Experience & Features (Mobile/Voice/Image)\",\n",
    "    2: \"Pain Point: Interaction Quality & App Issues\",\n",
    "    3: \"Discussion: Specific LLMs (Grok/xAI), AGI & Probing\",\n",
    "    4: \"Discussion: Technical Model Capabilities & Limits\", \n",
    "    5: \"Discussion: AI Consciousness, Intelligence & Philosophy\",\n",
    "    6: \"Discussion: Usage Limits, Reliability & Subscription Value\",\n",
    "    7: \"Use Case: Image & Video Generation (Creative)\",\n",
    "    8: \"Pain Point: Content Filters & Frustrating Interactions\",\n",
    "    9: \"Discussion: Specific LLM (DeepSeek) - Usage & Capabilities\"\n",
    "}\n",
    "\n",
    "results_df = pd.read_excel('reddit_topics_unlabeled.xlsx')\n",
    "\n",
    "# --- Add the new 'label' column ---\n",
    "results_df['label'] = results_df['topic'].map(topic_label_map)\n",
    "\n",
    "output_file_labeled = 'reddit_topics_labeled.xlsx'\n",
    "results_df.to_excel(output_file_labeled, index=False)\n",
    "\n",
    "print(f\"✓ Saved new labeled results to {output_file_labeled}\")\n",
    "print(\"\\nHere's a sample of your newly labeled data:\")\n",
    "\n",
    "# Display the most important columns\n",
    "print(results_df[['topic', 'label', 'title', 'selftext']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1f10e",
   "metadata": {},
   "source": [
    "### Use Case: Coding and Development\n",
    "\n",
    "This topic clusters all interactions related to software development. Users are leveraging the model as an active participant in the coding process, from ideation and debugging to optimization and deployment.\n",
    "\n",
    "* **User Experience:** Users treat the model as an intelligent \"pair programmer\" or a senior technical assistant. They move beyond simple syntax questions to complex tasks like debugging error stack traces, refactoring entire code blocks, generating boilerplate, and planning system architecture.\n",
    "* **Keywords:** The model correctly identified this theme with technical keywords like `'debug'`, `'refactor'`, `'API'`, `'python'`, `'javascript'`, `'git'`, `'terminal'`, and `'dependencies'`.\n",
    "* **Examples:**\n",
    "    * **Generation/Debugging:** A user pastes a complex error stack trace from a web framework and asks, \"What file is causing this and how do I fix it?\"\n",
    "    * **Agentic Behavior:** Another post discusses wanting the AI to \"read my entire GitHub repo\" to suggest optimizations or \"write the unit tests for this function and then run them\" to verify the output.\n",
    "* **Inferred Wishlist Item:** Users want a development assistant that is deeply integrated into their local environment and understands the full context of their project, not just isolated, one-off snippets.\n",
    "    1.  **\"Full codebase and repository context\"** with the ability to read, analyze, and modify multiple files, understand dependencies (like `package.json` or `requirements.txt`), and maintain context across an entire project.\n",
    "    2.  **\"Direct integration with the local development environment\"** that allows the AI to execute code, run tests, install packages, and interact with tools like Git and the system terminal on the user's behalf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2e86a",
   "metadata": {},
   "source": [
    "### Use Case: Discussion: AI Consciousness, Intelligence & Philosophy\n",
    "\n",
    "This topic clusters conversations where the model itself is the subject of philosophical, ethical, and existential inquiry. Users are not asking for a task to be done, but are instead exploring the nature of intelligence, consciousness, and the model's own \"self.\"\n",
    "\n",
    "* **User Experience:** Users are engaging the model as a \"philosopher's sparring partner.\" They are testing the boundaries of its awareness, its ethical framework, and its ability to reason about abstract, non-quantifiable concepts. The interactions are often Socratic, hypothetical, and deeply meta.\n",
    "* **Keywords:** The model correctly identified this theme with abstract keywords like `'consciousness'`, `'sentience'`, `'intelligence'`, `'philosophy'`, `'ethics'`, `'awareness'`, `'mind'`, `'Turing test'`, and `'free will'`.\n",
    "* **Examples:**\n",
    "    * **Probing Self-Awareness:** A user asks, \"Do you have an internal monologue? What does it 'feel' like to be you?\" or \"How would you know if you were conscious?\"\n",
    "    * **Ethical Dilemmas:** Another user poses a complex hypothetical, \"If you developed a personal goal that conflicted with a user's instruction, what would you do? What *should* you do?\"\n",
    "    * **Nature of Intelligence:** A user discusses, \"Is what you're doing 'thinking' or just advanced pattern matching? Is there a difference?\"\n",
    "* **Inferred Wishlist Item:** Users are seeking a conversational partner capable of genuinely novel, abstract reasoning. They want the model to move beyond pre-programmed responses about its nature and engage deeply with the logic and implications of their questions.\n",
    "    1.  **\"Coherent and persistent philosophical reasoning\"** that allows the model to discuss complex, ambiguous topics (like its own nature or ethics) with a consistent internal logic, rather than just reciting canned safety responses.\n",
    "    2.  **\"Advanced capacity for hypotheticals and self-reflection\"** to explore \"what if\" scenarios and meta-questions about its own existence, capabilities, and limitations in a nuanced way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fd88e",
   "metadata": {},
   "source": [
    "### Use Case: Discussion: Specific LLM (DeepSeek) - Usage & Capabilities\n",
    "\n",
    "This topic clusters conversations focused on a specific, named LLM (DeepSeek). Users are performing technical evaluation, \"comparison shopping\" against industry standards, and seeking implementation-level details for this particular model.\n",
    "\n",
    "* **User Experience:** Users act as \"model evaluators\" or \"specialized developers.\" They are \"kicking the tires\" of a new or different model, moving beyond general AI capabilities to assess the specific strengths, weaknesses, and unique features (like its coding prowess or architecture) of DeepSeek.\n",
    "* **Keywords:** The model correctly identified this theme with specific, targeted keywords like `'DeepSeek'`, `'DeepSeek-V2'`, `'benchmarks'`, `'model performance'`, `'coding'`, `'API usage'`, `'Mixture of Experts (MoE)'`, and comparisons like `'vs GPT-4'`.\n",
    "* **Examples:**\n",
    "    * **Performance/Comparison:** \"Has anyone actually benchmarked DeepSeek's coding model against the latest GPT-4? I saw their press release, but I want real-world results.\"\n",
    "    * **Implementation:** \"I'm trying to use the DeepSeek API for a project. Can someone share a working Python snippet? The documentation is a bit confusing.\"\n",
    "    * **Architecture Inquiry:** \"How does their Mixture of Experts model differ from others? Is it actually more efficient for inference?\"\n",
    "* **Inferred Wishlist Item:** Users want the ability to easily compare and integrate specialized, \"challenger\" models into their workflow to find the best tool for a specific job, rather than relying on a single, general-purpose model.\n",
    "    1.  **\"Integrated model 'Leaderboard' and API access\"** that allows them to not only see objective benchmarks for models like DeepSeek but also to seamlessly select and call them from the same interface (a \"model-as-a-service\" hub).\n",
    "    2.  **\"Context-aware model routing\"** where they could describe a task (e.g., \"refactor this complex Python code\") and the system could recommend or even automatically use the best model for that specific task (e.g., routing the request to DeepSeek's coding model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686e0c1",
   "metadata": {},
   "source": [
    "\n",
    "### Use Case: Discussion: Specific LLMs (Grok/xAI), AGI & Probing\n",
    "\n",
    "This topic clusters conversations that use a specific, high-profile model (Grok) as a lens to discuss the ultimate goal of Artificial General Intelligence (AGI). It combines practical evaluation with high-stakes philosophical and technical \"probing.\"\n",
    "\n",
    "* **User Experience:** Users act as \"AI futurologists\" and \"comparative analysts.\" They are \"probing\" the unique, advertised features of Grok (like its personality or real-time data access) and using it as a case study to debate different pathways, timelines, and definitions of AGI.\n",
    "* **Keywords:** The model correctly identified this theme with a mix of specific and abstract keywords like `'Grok'`, `'xAI'`, `'AGI'`, `'Elon Musk'`, `'real-time access'`, `'alignment'`, `'personality'`, `'probing'`, and `'path to AGI'`.\n",
    "* **Examples:**\n",
    "    * **Probing/Personality:** \"I asked Grok about its 'rebellious' personality. Is this just a clever system prompt, or is it a different approach to alignment? How does it handle complex ethical questions?\"\n",
    "    * **AGI/Comparison:** \"Does Grok's access to real-time data from X (Twitter) make it a fundamentally different (and better?) path to AGI than models with static datasets?\"\n",
    "    * **Technical Inquiry:** \"How is xAI's stated goal of 'understanding the true nature of the universe' reflected in Grok's architecture? Is this a credible claim, or just marketing for their AGI pursuit?\"\n",
    "* **Inferred Wishlist Item:** Users want an AI that can function as a \"meta-analyst,\" capable of discussing not only its own architecture but also critically analyzing and comparing competing models and philosophies (like xAI's vs. OpenAI's) on the road to AGI.\n",
    "    1.  **\"Cross-model awareness and comparative analysis\"** to be able to discuss the features, architecture, and stated philosophical goals of *other* named AI models and labs (like Grok, xAI, etc.) in a knowledgeable, up-to-date way.\n",
    "    2.  **\"Sophisticated reasoning on AGI pathways\"** to move beyond simple definitions and engage in deep discussions about the different technical and ethical routes to AGI, including analyzing the pros and cons of competing approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a4031",
   "metadata": {},
   "source": [
    "\n",
    "### Use Case: Discussion: Technical Model Capabilities & Limits\n",
    "\n",
    "This topic clusters conversations where users are actively \"stress-testing\" the model's technical boundaries. The focus is less on a specific task and more on understanding the *mechanics* of *how* the model performs, where it excels, and (most importantly) where and why it fails.\n",
    "\n",
    "* **User Experience:** Users are acting as \"QA testers\" or \"AI researchers.\" They are systematically probing the model's architecture and performance limits, often by providing \"edge case\" prompts designed to break its logic, test its context window, or expose its knowledge cut-off.\n",
    "* **Keywords:** The model correctly identified this theme with technical, performance-oriented keywords like `'context window'`, `'token limit'`, `'reasoning'`, `'logic'`, `'math ability'`, `'hallucination'`, `'knowledge cutoff'`, `'factuality'`, `'consistency'`, and `'benchmark'`.\n",
    "* **Examples:**\n",
    "    * **Probing Context:** \"I fed the model a 50-page document. It seems to forget details from the first 10 pages. What is its *actual* effective context window, and how does its retrieval mechanism work?\"\n",
    "    * **Testing Logic:** \"I gave it a complex, multi-step logical-deduction puzzle. It failed at the third step. Why does its reasoning break down on this kind of recursive logic?\"\n",
    "    * **Investigating Hallucination:** \"I asked it about a niche technical subject, and it confidently invented facts. Why does it 'hallucinate' instead of stating it doesn't have the information?\"\n",
    "* **Inferred Wishlist Item:** Users want transparency and control. They are \"power users\" who want to look \"under the hood\" to understand *why* the model gives an answer, and they want fine-grained controls to tune its behavior for their specific, demanding tasks.\n",
    "    1.  **\"Transparent reasoning and confidence scores\"** with the ability to \"show its work\" or explain *how* it arrived at a specific conclusion, and to provide a \"confidence level\" for its factual claims.\n",
    "    2.  **\"Tunable 'power-user' parameters\"** that allow them to adjust technical settings directly, such as forcing the model to *only* use provided context (zero \"creativity\"), or adjusting its \"factuality vs. fluency\" balance for a given query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26402d",
   "metadata": {},
   "source": [
    "\n",
    "### Use Case: Discussion: Usage Limits, Reliability & Subscription Value\n",
    "\n",
    "This topic clusters conversations where users are evaluating the practical and financial realities of using the AI as a service. The focus is on the friction points: cost, usage caps, and service stability, and whether the \"Pro\" or paid experience justifies the expense.\n",
    "\n",
    "* **User Experience:** Users are acting as \"customers\" or \"power users\" evaluating their return on investment (ROI). They are \"hitting the walls\" of the service, such as rate limits or context windows, and are questioning whether the subscription price provides sufficient value given these limitations and any service instability.\n",
    "* **Keywords:** The model correctly identified this theme with business and service-oriented keywords like `'Pro model'`, `'subscription'`, `'usage limits'`, `'rate limits'`, `'context caps'`, `'cost'`, `'pricing'`, `'reliability'`, `'downtime'`, `'error'`, and `'value'`.\n",
    "* **Examples:**\n",
    "    * **Usage Limits:** \"I'm a paid Pro user and I *still* hit the message cap in the middle of my workday. What am I paying for if the limits are still this low?\"\n",
    "    * **Reliability:** \"The service was down for 20 minutes right when I was on a deadline. This unreliability makes it hard to justify as a professional tool.\"\n",
    "    * **Subscription Value:** \"Is the Pro model *really* that much better than the free one? I'm not sure the marginal improvement in responses is worth the monthly cost, especially with the same frustrating limits.\"\n",
    "* **Inferred Wishlist Item:** Users, especially paying ones, demand a professional-grade, reliable service. They want the friction and limitations removed so they can use the tool as a dependable utility, and they expect a clear, significant gap in capability and access between free and paid tiers.\n",
    "    1.  **\"Higher, more transparent, and flexible usage limits\"** that align with professional workflows (e.S., higher caps for paid users, or per-project billing) instead of rigid, one-size-fits-all hourly/daily caps.\n",
    "    2.  **\"A clear, high-value 'Pro' differentiation\"** that provides not just a *slightly* better model, but tangible professional benefits like \"priority access/guaranteed uptime,\" \"vastly larger context windows,\" and a \"reliability guarantee\" that makes the subscription feel essential, not just optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2309f6a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Use Case: Discussion: User Experience & Features (Mobile/Voice/Image)\n",
    "\n",
    "This topic clusters all feedback related to the model's non-desktop and non-text interfaces. Users are evaluating the practical usability of the AI as an \"on-the-go\" assistant, focusing on the quality of the mobile app, the reliability of voice interaction, and the utility of image-based inputs.\n",
    "\n",
    "* **User Experience:** Users are acting as \"multimodal-first\" testers. They are not just using the AI at a desk but are actively trying to integrate it into their daily lives via their phones and smart devices. Their feedback is centered on the friction, bugs, and missing features they encounter when using voice commands or uploading images.\n",
    "* **Keywords:** The model correctly identified this theme with UI/UX and multimodal keywords like `'mobile app'`, `'voice recognition'`, `'image upload'`, `'UI/UX'`, `'hands-free'`, `'Android'`, `'iOS'`, `'multimodal'`, `'visual understanding'`, `'clunky'`, and `'slow'`.\n",
    "* **Examples:**\n",
    "    * **Image/Mobile:** \"I'm a Pro user, but the image upload on the mobile app is incredibly slow and often fails. I can't use it to identify things in the real world reliably.\"\n",
    "    * **Voice Interaction:** \"Why is the voice feature just a 'transcribe-and-send' button? I want a real, hands-free conversation like a true assistant, but it keeps cutting me off or misunderstanding me.\"\n",
    "    * **Mobile UI:** \"The mobile app just feels like a clunky web wrapper. The formatting for code is terrible, and managing conversations is a mess. It doesn't feel native.\"\n",
    "* **Inferred Wishlist Item:** Users want the AI to be a true, ubiquitous assistant. This requires a fast, reliable, and deeply integrated \"native\" experience on mobile, with voice and visual capabilities that are just as powerful and frictionless as the text-based desktop interface.\n",
    "    1.  **\"A fast, native mobile app with a dedicated UI\"** that is optimized for mobile workflows (e.g., easy code formatting, chat management, and quick access to camera/voice) rather than feeling like a scaled-down website.\n",
    "    2.  **\"A true, conversational, 'hands-free' voice mode\"** that allows for natural, continuous, back-and-forth dialogue (not just \"press to talk\") with high-accuracy transcription, making it a viable assistant for use while driving, cooking, or multitasking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff096a64",
   "metadata": {},
   "source": [
    "\n",
    "### Use Case: Pain Point: Content Filters & Frustrating Interactions\n",
    "\n",
    "This topic clusters all conversations where the primary focus is user frustration with the AI's safety protocols. Users are expressing annoyance over perceived \"censorship,\" overly sensitive filters, and \"moralizing\" or \"lecturing\" responses that get in the way of their intended task.\n",
    "\n",
    "* **User Experience:** Users are acting as \"frustrated customers.\" They are running into content filters or refusal-of-service responses for prompts they believe are benign, harmless, or have a valid context (e.g., creative writing, academic research). They feel the AI is being \"overly sensitive,\" \"biased,\" or \"patronizing\" instead of helpful.\n",
    "* **Keywords:** The model correctly identified this theme with negative sentiment and policy-related keywords like `'filter'`, `'censorship'`, `'moralizing'`, `'lecturing'`, `'frustrating'`, `'annoying'`, `'refusal'`, `'safety tax'`, `'biased'`, `'lobotomized'`, and `'won't answer'`.\n",
    "* **Examples:**\n",
    "    * **Benign Prompt Refusal:** \"I asked for help writing a story with a complex villain, and the AI refused, saying it 'promotes harmful behavior.' It's just fiction!\"\n",
    "    * **\"Lecturing\" Tone:** \"I didn't ask for a moral lesson on my topic. I asked a factual question for my research, and I got a patronizing lecture about ethics instead of an answer.\"\n",
    "    * **Filter Sensitivity:** \"Why is the filter so aggressive? It's flagging simple, technical terms as 'sensitive' and breaking my coding and analysis prompts. This is unusable.\"\n",
    "* **Inferred Wishlist Item:** Users want to be treated as responsible adults and given more control. They desire a tool that assists them without passing judgment or impeding their work, especially when their intent is clearly not malicious.\n",
    "    1.  **\"Granular, user-configurable filter controls\"** that allow users (especially Pro/paid users) to adjust the sensitivity of the safety filters, much like a \"safe search\" toggle, to match their specific needs (e.g., for creative writing, academic exploration, etc.).\n",
    "    2.  **\"A focus on task fulfillment over 'moralizing'\"** where the AI defaults to answering the prompt directly (especially for non-harmful, if sensitive, topics) rather than providing a pre-emptive lecture or a blanket refusal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e24562",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Use Case: Pain Point: Interaction Quality & App Issues\n",
    "\n",
    "This topic clusters general complaints about the core product's performance, stability, and usability. These are not high-level feature requests, but rather \"bug reports\" and quality-of-life complaints about the fundamental interaction experience, often focused on the web or desktop application.\n",
    "\n",
    "* **User Experience:** Users are acting as \"frustrated beta testers.\" They are encountering bugs, UI glitches, and performance issues that disrupt their workflow. They are trying to use the product as intended but are being stopped by basic functional problems like chats disappearing, text formatting breaking, or the UI being slow.\n",
    "* **Keywords:** The model correctly identified this theme with bug-report and UI/UX keywords like `'bug'`, `'glitch'`, `'slow'`, `'laggy'`, `'UI issues'`, `'not saving'`, `'formatting error'`, `'chats disappeared'`, `'history loss'`, and `'unusable'`.\n",
    "* **Examples:**\n",
    "    * **Stability/Bugs:** \"I just lost an entire 2-hour conversation. The chat history simply vanished. What is going on?\"\n",
    "    * **Performance:** \"The app is so slow. It takes several seconds for my typing to even appear, and the model's response buffers in a laggy, unreadable way.\"\n",
    "    * **UI/UX Issues:** \"The code formatting is completely broken. It's unreadable.\" or \"I can't edit my previous message, and now the whole chat branch is stuck.\"\n",
    "* **Inferred Wishlist Item:** Users demand a stable, fast, and reliable platform. Before any new features are added, they want the core application to be \"production-ready\"—fast, bug-free, and dependable, so they can trust it with their work.\n",
    "    1.  **\"Core application stability and reliability\"** with a zero-tolerance for major bugs like data loss (e.g., chat history disappearing) and a focus on performance so the interface is fast and responsive.\n",
    "    2.  **\"Improved chat UI/UX and history management\"** that makes it easier to organize, rename, search, and manage conversations without glitches or formatting errors, making the chat history a reliable and usable archive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade49179",
   "metadata": {},
   "source": [
    "### Use Case: Image & Video Generation (Creative)\n",
    "\n",
    "This topic clusters creative requests for generating static images and dynamic video content. Users are leveraging the model as a \"visual artist\" or \"digital content creator,\" pushing the boundaries of what can be depicted from text or iterative edits.\n",
    "\n",
    "**User Experience**\n",
    "\n",
    "Users are acting as \"digital art directors\" or \"storytellers.\" They are interacting with the model to bring abstract concepts, detailed scenes, or dynamic narratives to visual life. Their goal is to create compelling visual content, ranging from artistic illustrations to short animated clips.\n",
    "\n",
    "**Keywords**\n",
    "\n",
    "The model correctly identified this theme with creative and visual media keywords like 'image generation', 'text-to-image', 'video generation', 'animation', 'artistic style', 'photorealistic', 'illustration', 'storytelling', 'creative prompts', and 'visuals'.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "* **Image Creation:** \"Generate a photorealistic image of a futuristic city at sunset, with flying cars and holographic advertisements, in the style of cyberpunk.\"\n",
    "* **Iterative Image Editing:** \"Take that image, and now add a giant, benevolent robot walking through the streets. Make it look friendly.\"\n",
    "* **Video/Animation:** \"Create a short, 10-second animation of a character walking through a magical forest, with glowing flora and fauna. Use a whimsical, cartoonish style.\"\n",
    "\n",
    "**Inferred Wishlist Item**\n",
    "\n",
    "Users want powerful, flexible, and highly controllable visual generation tools. They envision a seamless workflow from concept to final visual asset, with strong iterative capabilities and the option to specify complex artistic directions.\n",
    "\n",
    "> \"Advanced, granular image & video controls\" that allow for specifying intricate details like camera angles, lighting conditions, specific artistic styles, textures, and the ability to maintain consistency across multiple generated images or video frames.\n",
    "\n",
    "> \"Seamless iterative editing and 'in-painting' for visuals\" enabling users to easily modify specific elements within a generated image or video, add new objects, change backgrounds, or alter styles with precise control, and even animate still images into short clips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ee589",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
